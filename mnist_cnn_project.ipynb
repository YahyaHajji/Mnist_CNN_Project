{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YahyaHajji/Mnist_CNN_Project/blob/master/mnist_cnn_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Import Required Libraries**"
      ],
      "metadata": {
        "id": "ewDTL4hYevlS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4Jw83uzrxqm"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Load and Prepare the MNIST Dataset**"
      ],
      "metadata": {
        "id": "36yI38tue4Sy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msDTOZ8TsmTy"
      },
      "outputs": [],
      "source": [
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"Original shapes:\")\n",
        "print(f\"Training data: {x_train.shape}\")\n",
        "print(f\"Test data: {x_test.shape}\")\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Reshape data to include channel dimension for CNN\n",
        "# From (samples, 28, 28) to (samples, 28, 28, 1)\n",
        "x_train_cnn = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test_cnn = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print(\"\\nReshaped for CNN:\")\n",
        "print(f\"Training data: {x_train_cnn.shape}\")\n",
        "print(f\"Test data: {x_test_cnn.shape}\")\n",
        "\n",
        "# Visualize some samples\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(x_train[i], cmap='gray')\n",
        "    plt.title(f\"Label: {y_train[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.suptitle(\"Sample MNIST Digits\", fontsize=14, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Build the CNN Model**"
      ],
      "metadata": {
        "id": "FT4Nq44lit3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVuXXtpms0L0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# Create CNN model\n",
        "cnn_model = Sequential([\n",
        "    Input(shape=(28, 28, 1)), # Explicitly define the input layer\n",
        "    # First Convolutional Block\n",
        "    Conv2D(32, (3, 3), activation='relu'), # input_shape is now defined by the Input layer\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Second Convolutional Block (optional, for better performance)\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten and Dense layers\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # Prevent overfitting\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Display model architecture\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Compile the CNN Model**"
      ],
      "metadata": {
        "id": "xbr4kSKijgHb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fi25BwMtS0j"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "cnn_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"‚úÖ CNN Model compiled successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Train the CNN Model**"
      ],
      "metadata": {
        "id": "lO0i1fOGkHhH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwCK7UX1utr8"
      },
      "outputs": [],
      "source": [
        "# Train the CNN model\n",
        "print(\"üöÄ Training CNN Model...\")\n",
        "start_time = time.time()\n",
        "\n",
        "cnn_history = cnn_model.fit(\n",
        "    x_train_cnn, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_test_cnn, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"\\n‚è±Ô∏è Training completed in {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Build and Train Simple ANN for Comparison**"
      ],
      "metadata": {
        "id": "32wlLfTOlP7e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N29b28vuv71"
      },
      "outputs": [],
      "source": [
        "# Build simple ANN (like in previous project)\n",
        "ann_model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "ann_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display ANN architecture\n",
        "print(\"ANN Model Architecture:\")\n",
        "ann_model.summary()\n",
        "\n",
        "# Train ANN model\n",
        "print(\"\\nüöÄ Training ANN Model for comparison...\")\n",
        "ann_start_time = time.time()\n",
        "\n",
        "ann_history = ann_model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "ann_training_time = time.time() - ann_start_time\n",
        "print(f\"\\n‚è±Ô∏è ANN Training completed in {ann_training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Evaluate Both Models**"
      ],
      "metadata": {
        "id": "-aR1pX5koTlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate CNN\n",
        "cnn_loss, cnn_accuracy = cnn_model.evaluate(x_test_cnn, y_test, verbose=0)\n",
        "\n",
        "# Evaluate ANN\n",
        "ann_loss, ann_accuracy = ann_model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Display comparison\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä MODEL COMPARISON RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüß† CNN Model:\")\n",
        "print(f\"   Test Accuracy: {cnn_accuracy:.4f} ({cnn_accuracy*100:.2f}%)\")\n",
        "print(f\"   Test Loss: {cnn_loss:.4f}\")\n",
        "print(f\"   Training Time: {training_time:.2f}s\")\n",
        "\n",
        "print(f\"\\nüìù ANN Model:\")\n",
        "print(f\"   Test Accuracy: {ann_accuracy:.4f} ({ann_accuracy*100:.2f}%)\")\n",
        "print(f\"   Test Loss: {ann_loss:.4f}\")\n",
        "print(f\"   Training Time: {ann_training_time:.2f}s\")\n",
        "\n",
        "print(f\"\\n‚ú® Improvement:\")\n",
        "improvement = (cnn_accuracy - ann_accuracy) * 100\n",
        "print(f\"   CNN is {improvement:.2f}% more accurate than ANN\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "N3bdOd-wveON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 9: Visualize Training History Comparison**"
      ],
      "metadata": {
        "id": "Ibo_CVc6oZve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# CNN Accuracy\n",
        "axes[0, 0].plot(cnn_history.history['accuracy'], label='Training', linewidth=2)\n",
        "axes[0, 0].plot(cnn_history.history['val_accuracy'], label='Validation', linewidth=2)\n",
        "axes[0, 0].set_title('CNN - Accuracy', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Accuracy')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# CNN Loss\n",
        "axes[0, 1].plot(cnn_history.history['loss'], label='Training', linewidth=2)\n",
        "axes[0, 1].plot(cnn_history.history['val_loss'], label='Validation', linewidth=2)\n",
        "axes[0, 1].set_title('CNN - Loss', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Loss')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# ANN Accuracy\n",
        "axes[1, 0].plot(ann_history.history['accuracy'], label='Training', linewidth=2)\n",
        "axes[1, 0].plot(ann_history.history['val_accuracy'], label='Validation', linewidth=2)\n",
        "axes[1, 0].set_title('ANN - Accuracy', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Accuracy')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# ANN Loss\n",
        "axes[1, 1].plot(ann_history.history['loss'], label='Training', linewidth=2)\n",
        "axes[1, 1].plot(ann_history.history['val_loss'], label='Validation', linewidth=2)\n",
        "axes[1, 1].set_title('ANN - Loss', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Loss')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vySNnHXyvp63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 10: Side-by-Side Accuracy Comparison**"
      ],
      "metadata": {
        "id": "Z5En_3orogxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create bar chart comparison\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "models = ['ANN', 'CNN']\n",
        "accuracies = [ann_accuracy * 100, cnn_accuracy * 100]\n",
        "colors = ['#FF6B6B', '#4ECDC4']\n",
        "\n",
        "bars = ax.bar(models, accuracies, color=colors, width=0.5, edgecolor='black', linewidth=2)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{acc:.2f}%',\n",
        "            ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
        "\n",
        "ax.set_ylabel('Test Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('ANN vs CNN Performance Comparison on MNIST', fontsize=14, fontweight='bold')\n",
        "ax.set_ylim([95, 100])\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bgqnBYcUvq8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 11: Test Predictions on Sample Images**"
      ],
      "metadata": {
        "id": "dIdCi4HUomvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with both models\n",
        "cnn_predictions = cnn_model.predict(x_test_cnn[:20])\n",
        "ann_predictions = ann_model.predict(x_test[:20])\n",
        "\n",
        "# Visualize predictions\n",
        "fig, axes = plt.subplots(4, 5, figsize=(15, 10))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(x_test[i], cmap='gray')\n",
        "\n",
        "    cnn_pred = np.argmax(cnn_predictions[i])\n",
        "    ann_pred = np.argmax(ann_predictions[i])\n",
        "    true_label = y_test[i]\n",
        "\n",
        "    # Color code: green if both correct, yellow if only CNN correct, red if both wrong\n",
        "    if cnn_pred == true_label and ann_pred == true_label:\n",
        "        color = 'green'\n",
        "        status = '‚úì‚úì'\n",
        "    elif cnn_pred == true_label and ann_pred != true_label:\n",
        "        color = 'orange'\n",
        "        status = 'CNN‚úì'\n",
        "    elif cnn_pred != true_label and ann_pred == true_label:\n",
        "        color = 'blue'\n",
        "        status = 'ANN‚úì'\n",
        "    else:\n",
        "        color = 'red'\n",
        "        status = '‚úó‚úó'\n",
        "\n",
        "    ax.set_title(f'True: {true_label}\\nCNN: {cnn_pred} | ANN: {ann_pred}\\n{status}',\n",
        "                 color=color, fontsize=9, fontweight='bold')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle('Prediction Comparison: CNN vs ANN', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7tvj636Gvv2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 12: Analyze Overfitting**"
      ],
      "metadata": {
        "id": "5q0ywXS1o3eW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for overfitting\n",
        "def check_overfitting(history, model_name):\n",
        "    final_train_acc = history.history['accuracy'][-1]\n",
        "    final_val_acc = history.history['val_accuracy'][-1]\n",
        "    gap = (final_train_acc - final_val_acc) * 100\n",
        "\n",
        "    print(f\"\\n{model_name} Overfitting Analysis:\")\n",
        "    print(f\"  Final Training Accuracy: {final_train_acc*100:.2f}%\")\n",
        "    print(f\"  Final Validation Accuracy: {final_val_acc*100:.2f}%\")\n",
        "    print(f\"  Gap: {gap:.2f}%\")\n",
        "\n",
        "    if gap < 2:\n",
        "        print(f\"  Status: ‚úÖ No significant overfitting\")\n",
        "    elif gap < 5:\n",
        "        print(f\"  Status: ‚ö†Ô∏è Slight overfitting\")\n",
        "    else:\n",
        "        print(f\"  Status: ‚ùå Overfitting detected\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "check_overfitting(cnn_history, \"CNN\")\n",
        "check_overfitting(ann_history, \"ANN\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "xQPLuPJ3v0e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 13: Confusion Matrix (Optional Advanced)**"
      ],
      "metadata": {
        "id": "zEjm3NsNpDhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Get predictions for entire test set\n",
        "cnn_pred_classes = np.argmax(cnn_model.predict(x_test_cnn), axis=1)\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, cnn_pred_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=range(10), yticklabels=range(10))\n",
        "plt.title('CNN Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nüìä CNN Classification Report:\")\n",
        "print(classification_report(y_test, cnn_pred_classes, target_names=[str(i) for i in range(10)]))"
      ],
      "metadata": {
        "id": "87qFDuK9wIzv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOTJzTxyPuKJZuzfPLQh4lj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}